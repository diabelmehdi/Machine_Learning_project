{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils as utils\n",
    "from keras.layers import Dropout, Dense, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import  f1_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'object1/side1-0.5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6d2b20f0fdf4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'side1-0.5.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'side1-0.8.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'side1-1.2m.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'side1-1.6.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'side2-0.5.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'side2-0.8.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'side2-1.2.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'side2-1.6.csv'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object1/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object1/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mc3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object1/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'object1/side1-0.5.csv'"
     ]
    }
   ],
   "source": [
    "#object 1\n",
    "s = ['side1-0.5.csv', 'side1-0.8.csv', 'side1-1.2m.csv', 'side1-1.6.csv', 'side2-0.5.csv', 'side2-0.8.csv', 'side2-1.2.csv', 'side2-1.6.csv']\n",
    "\n",
    "c = pd.read_csv('object1/'+s[0])\n",
    "c2 = pd.read_csv('object1/'+s[1])\n",
    "c3 = pd.read_csv('object1/'+s[2])\n",
    "c4 = pd.read_csv('object1/'+s[3])\n",
    "c5 = pd.read_csv('object1/'+s[4])\n",
    "c6 = pd.read_csv('object1/'+s[5])\n",
    "c7 = pd.read_csv('object1/'+s[6])\n",
    "c8 = pd.read_csv('object1/'+s[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'object2/front-black-1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ee7210668d75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m      'frontblack-0.8.csv','frontblack-1.5.csv', 'frontblack-1.6.csv', 'frontyellow-0.8.csv','frontyellow-1.6.csv',]\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object2/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mo2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object2/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mo3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object2/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1178\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1179\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2008\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'object2/front-black-1.csv'"
     ]
    }
   ],
   "source": [
    "#object 2\n",
    "s = ['front-black-1.csv', 'front-black-1.2.csv','front-black0.5.csv','front-yellow-1.2.csv', 'front-yellow-1.csv','front-yellow0.5.csv',\n",
    "     'frontblack-0.8.csv','frontblack-1.5.csv', 'frontblack-1.6.csv', 'frontyellow-0.8.csv','frontyellow-1.6.csv',]\n",
    "\n",
    "o = pd.read_csv('object2/'+s[0])\n",
    "o2 = pd.read_csv('object2/'+s[1])\n",
    "o3 = pd.read_csv('object2/'+s[2])\n",
    "o4 = pd.read_csv('object2/'+s[3])\n",
    "o5 = pd.read_csv('object2/'+s[4])\n",
    "o6 = pd.read_csv('object2/'+s[5])\n",
    "o7 = pd.read_csv('object2/'+s[6])\n",
    "o8 = pd.read_csv('object2/'+s[7])\n",
    "o9 = pd.read_csv('object2/'+s[8])\n",
    "o10 = pd.read_csv('object2/'+s[9])\n",
    "o11 = pd.read_csv('object2/'+s[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepairing training set !!! test_data %20\n",
    "\n",
    "\n",
    "#label 0 in y\n",
    "dtr1 = c[c.columns[24:30]] \n",
    "dtr2 = c2[c2.columns[24:30]] \n",
    "dtr3 = c3[c3.columns[24:30]] \n",
    "dtr4 = c4[c4.columns[24:30]] \n",
    "dtr5 = c5[c5.columns[24:30]] \n",
    "dtr6 = c6[c6.columns[24:30]]  \n",
    "dtr7 = c7[c7.columns[24:30]]  \n",
    "dtr8 = c8[c8.columns[24:30]] \n",
    "\n",
    "#label 1 in y\n",
    "dt1 = o[o.columns[24:30]]  \n",
    "dt2 = o2[o2.columns[24:30]] \n",
    "dt3 = o3[o3.columns[24:30]] \n",
    "dt4 = o4[o4.columns[24:30]] \n",
    "dt5 = o5[o5.columns[24:30]]  \n",
    "dt6 = o6[o6.columns[24:30]] \n",
    "dt7 = o7[o7.columns[24:30]] \n",
    "dt8 = o8[o8.columns[24:30]] \n",
    "dt9 = o9[o9.columns[24:30]]  \n",
    "dt10 = o10[o10.columns[24:30]] \n",
    "dt11 = o11[o11.columns[24:30]] \n",
    "\n",
    "dy_test = [0]* 48 +[1] * 66\n",
    "dy_test = np.asarray(dy_test)\n",
    "\n",
    "d_test = pd.concat([dtr1, dtr2, dtr3, dtr4, dtr5, dtr6, dtr7, dtr8, dt1, dt2, dt3, dt4, dt5, dt6, dt7, dt8, dt9, dt10, dt11], axis=1, join='inner') \n",
    "dy_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepairing training set !!! Validation_data %20\n",
    "\n",
    "dtr1 = c[c.columns[18:24]] \n",
    "dtr2 = c2[c2.columns[18:24]] \n",
    "dtr3 = c3[c3.columns[18:24]] \n",
    "dtr4 = c4[c4.columns[18:24]] \n",
    "dtr5 = c5[c5.columns[18:24]] \n",
    "dtr6 = c6[c6.columns[18:24]] \n",
    "dtr7 = c7[c7.columns[18:24]] \n",
    "dtr8 = c8[c8.columns[18:24]] \n",
    "\n",
    "dt1 = o[o.columns[18:24]] \n",
    "dt2 = o2[o2.columns[18:24]] \n",
    "dt3 = o3[o3.columns[18:24]] \n",
    "dt4 = o4[o4.columns[18:24]] \n",
    "dt5 = o5[o5.columns[18:24]] \n",
    "dt6 = o6[o6.columns[18:24]] \n",
    "dt7 = o7[o7.columns[18:24]] \n",
    "dt8 = o8[o8.columns[18:24]] \n",
    "dt9 = o9[o9.columns[18:24]] \n",
    "dt10 = o10[o10.columns[18:24]] \n",
    "dt11 = o11[o11.columns[18:24]] \n",
    "\n",
    "dy_val = [0]* 48 +[1] * 66\n",
    "dy_val = np.asarray(dy_val)\n",
    "\n",
    "d_val = pd.concat([dtr1, dtr2, dtr3, dtr4, dtr5, dtr6, dtr7, dtr8, dt1, dt2, dt3, dt4, dt5, dt6, dt7, dt8, dt9, dt10, dt11], axis=1, join='inner') \n",
    "dy_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepairing training set !!! train_data %60\n",
    "\n",
    "dtr1 = c[c.columns[:18]] \n",
    "dtr2 = c2[c2.columns[:18]] \n",
    "dtr3 = c3[c3.columns[:18]] \n",
    "dtr4 = c4[c4.columns[:18]] \n",
    "dtr5 = c5[c5.columns[:18]] \n",
    "dtr6 = c6[c6.columns[:18]] \n",
    "dtr7 = c7[c7.columns[:18]] \n",
    "dtr8 = c8[c8.columns[:18]] \n",
    "\n",
    "dt1 = o[o.columns[:18]] \n",
    "dt2 = o2[o2.columns[:18]] \n",
    "dt3 = o3[o3.columns[:18]] \n",
    "dt4 = o4[o4.columns[:18]] \n",
    "dt5 = o5[o5.columns[:18]] \n",
    "dt6 = o6[o6.columns[:18]] \n",
    "dt7 = o7[o7.columns[:18]] \n",
    "dt8 = o8[o8.columns[:18]] \n",
    "dt9 = o9[o9.columns[:18]] \n",
    "dt10 = o10[o10.columns[:18]] \n",
    "dt11 = o11[o11.columns[:18]] \n",
    "\n",
    "dy_tr = [0]* 144 +[1] * 198\n",
    "dy_tr = np.asarray(dy_tr)\n",
    "\n",
    "d_train = pd.concat([dtr1, dtr2, dtr3, dtr4, dtr5, dtr6, dtr7, dtr8, dt1, dt2, dt3, dt4, dt5, dt6, dt7, dt8, dt9, dt10, dt11], axis=1, join='inner') \n",
    "d_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping DATA X_train\n",
    "\n",
    "X_train = d_train.transpose()\n",
    "X_train = np.array(X_train.values.tolist())\n",
    "X_train = X_train.reshape(342,1, 16384,1)\n",
    "\n",
    "\n",
    "# Reshaping DATA X_validation\n",
    "\n",
    "X_validation = d_val.transpose()\n",
    "X_validation = np.array(X_validation.values.tolist())\n",
    "X_validation = X_validation.reshape(114,1, 16384,1)\n",
    "\n",
    "# Reshaping DATA X_test\n",
    "\n",
    "X_test = d_test.transpose()\n",
    "X_test = np.array(X_test.values.tolist())\n",
    "X_test = X_test.reshape(114,1, 16384,1)\n",
    "\n",
    "# Y train assigning\n",
    "y_train = dy_tr\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "# Y validation assigning\n",
    "y_validation = dy_val\n",
    "y_validation = to_categorical(y_validation)\n",
    "\n",
    "# Y test assigning\n",
    "y_test = dy_test\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 1st conv layer\n",
    "model.add(Conv2D(32, (1, 2), activation='relu', input_shape=(1,16384,1)))\n",
    "model.add(MaxPooling2D((1, 2), strides=(1, 2), padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "# 2nd conv layer\n",
    "model.add(keras.layers.Conv2D(32, (1, 2), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((1, 2), strides=(1, 2), padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# 3rd conv layer\n",
    "model.add(keras.layers.Conv2D(32, (1, 2), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((1, 2), strides=(1, 2), padding='same'))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "# flatten output and feed it into dense layer\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(80, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimiser,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=5, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0] .reshape(1,1,16384,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rounded_predictions = predict_classes(model, X_test[55] .reshape(1,1,16384,1));\n",
    "rounded_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ploting\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "  \n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "#\n",
    "# Plot the model accuracy vs Epochs\n",
    "#\n",
    "ax[0].plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "ax[0].plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "ax[0].set_title('Training &amp; Validation Accuracy', fontsize=16)\n",
    "ax[0].set_xlabel('Epochs', fontsize=16)\n",
    "ax[0].set_ylabel('Accuracy', fontsize=16)\n",
    "ax[0].legend()\n",
    "#\n",
    "# Plot the loss vs Epochs\n",
    "#\n",
    "ax[1].plot(epochs, loss_values, 'bx', label='Training loss') \n",
    "ax[1].plot(epochs, val_loss_values, 'r', label='Validation loss')\n",
    "ax[1].set_title('Training &amp; Validation Loss', fontsize=16)\n",
    "ax[1].set_xlabel('Epochs', fontsize=16)\n",
    "ax[1].set_ylabel('Loss', fontsize=16)\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('test_acc:',test_acc )\n",
    "print('test_loss:',test_loss )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_classes(self, x, batch_size=32, verbose=1):\n",
    "    '''Generate class predictions for the input samples\n",
    "    batch by batch.\n",
    "    # Arguments\n",
    "        x: input data, as a Numpy array or list of Numpy arrays\n",
    "            (if the model has multiple inputs).\n",
    "        batch_size: integer.\n",
    "        verbose: verbosity mode, 0 or 1.\n",
    "    # Returns\n",
    "        A numpy array of class predictions.\n",
    "    '''\n",
    "    proba = self.predict(x, batch_size=batch_size, verbose=verbose)\n",
    "    if proba.shape[-1] > 1:\n",
    "        return proba.argmax(axis=-1)\n",
    "    else:\n",
    "        return (proba > 0.5).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding predictions because of multiclasses\n",
    "rounded_predictions = predict_classes(model, X_test);\n",
    "rounded_labels=np.argmax(y_test, axis=1)\n",
    "cm = confusion_matrix(rounded_labels, rounded_predictions)\n",
    "\n",
    "# FP, FN, TP, TN\n",
    "FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "print(\"FP : \",FP)\n",
    "FN = cm.sum(axis=1) - np.diag(cm)\n",
    "print(\"FN : \",FN)\n",
    "TP = np.diag(cm)\n",
    "print(\"TP : \",TP)\n",
    "TN = cm.sum() - (FP + FN + TP)\n",
    "print(\"TN : \",TN)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\"TPR : \",TPR)\n",
    "\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "print(\"TNR : \",TNR)\n",
    "\n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "print(\"PPV : \", PPV)\n",
    "\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "print(\"NPV : \",NPV)\n",
    "\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "print(\"FPR : \",FPR)\n",
    "\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "print(\"FNR : \",FNR)\n",
    "\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "print(\"FDR : \",FDR)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "print(\"ACC : \",ACC)\n",
    "\n",
    "# F1 Score\n",
    "F1 = f1_score(rounded_labels, rounded_predictions)\n",
    "print(\"F1 Score : \", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "auc = roc_auc_score(rounded_labels, rounded_predictions)\n",
    "print('AUC: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(FPR, TPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For more information about ROC \n",
    "\n",
    "https://stackabuse.com/understanding-roc-curves-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Anvil prep\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install anvil-uplink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "import anvil.server\n",
    "import anvil.mpl_util\n",
    "\n",
    "anvil.server.connect(\"IENQAFSXPANG77AFDTYTC4E2-5XNVA4KIZCRITORA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def roc_elem(test_id):\n",
    "    \n",
    "    rounded_predictions = predict_classes(model, X_test);\n",
    "    rounded_labels=np.argmax(y_test, axis=1)\n",
    "    cm = confusion_matrix(rounded_labels, rounded_predictions)\n",
    "\n",
    "    # FP, FN, TP, TN\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "    \n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    \n",
    "    TP = np.diag(cm)\n",
    "    \n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "    TPR = TP/(TP+FN)\n",
    "\n",
    "    TNR = TN/(TN+FP) \n",
    "\n",
    "    NPV = TN/(TN+FN)\n",
    "\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    ACC = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "    F1 = f1_score(rounded_labels, rounded_predictions)\n",
    "    \n",
    "    return TP, TN, FP, FN, NPV, TNR, FDR, TPR, F1, ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@anvil.server.callable\n",
    "def obj_detect(test_id):\n",
    "    rounded_predictions = predict_classes(model, X_test[test_id].reshape(1,1,16384,1));\n",
    "    return rounded_predictions[0] + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cf290153e199>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import numpy as np\n",
    "\n",
    "@anvil.server.callable\n",
    "def obj_plot(test_id):\n",
    "    plt.plot(X_test[test_id].reshape(16384, 1))\n",
    "    return anvil.mpl_util.plot_image()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_test[0].reshape(16384, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
